#summary Development notes.
#labels Featured

= General Notes =
  * There are some duplicate docIDs in GOV2, and their scores will be the same.

= Index Organization Ideas =
  * Can we store all the block headers together at the front of each list? This should result in somewhat better processor cache utilization, since chunks will be closer together as well as the skipping information; but might not be worth it. In this case, the lexicon would need a pointer (offset) to the start of the appropriate block headers, plus a pointer (offset) to the start of the actual list data (for OR/single word queries) for when we don't need to decode block headers.

  * Another idea to eliminate the "wasted space" at the end of each block. This means that a chunk can span block headers (assuming it can span a maximum of 2 blocks only). Since we know the size of each chunk (stored in the block header), when we start decompressing a chunk, we know if it'll spill over to the next block. The PROBLEM with this scheme is that when a chunk spans across a block, we need to get the complete chunk data in a single array. However, our caching scheme (LRU) prevents this because consecutive blocks are not guaranteed to be placed consecutively in the cache (although it is likely they are). When using this caching scheme, we'd have to check whether the blocks that the chunk spans are consecutively placed, and if not we need to copy the chunk data into a new array and use it as input to the compression function. Note that this does not affect us when the index is completely in main memory, since the blocks are always consecutively placed in main memory.

= Parallel Indexing Capability =
  * Have command line options to specify the number of processes we want and fork off several irtk processes. Each process should create a unique folder for outputting index files (perhaps using the pid for the folder name). The parent that sets this up can split the files to index for each child process and pipe them into each child (through I/O redirection) and then die. Things like merging can be done independently within each folder. The final merge would have to be done by specifying the indices in each folder. Note that each process would need to record the docID offset for it's index. The final merge would have to take the offsets into account.

= Experiments to Run =
  * Benchmark indexing speed and query speed against zettair. Can also index with varbyte to make comparison fair.
  * To test decompression speeds, can use the loop over list function. This would ignore scoring function and other overheads.

= Commands to Keep in Mind =
  * *Run Valgrind*: `valgrind --tool=cachegrind --branch-sim=yes --cachegrind-out-file=cachegrind.out ./irtk --loop-over-index-data=gov index`
  * To drop caches in Linux (must be root):
    * *Free page cache*: `echo 1 > /proc/sys/vm/drop_caches`
    * *Free dentries and inodes*: `echo 2 > /proc/sys/vm/drop_caches`
    * *Free pagecache, dentries and inodes*: `echo 3 > /proc/sys/vm/drop_caches`